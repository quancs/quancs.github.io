<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on Changsheng Quan</title><link>https://quancs.github.io/zh-cn/blog/</link><description>Recent content in Blog on Changsheng Quan</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sat, 04 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://quancs.github.io/zh-cn/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>深度窄带语音分离</title><link>https://quancs.github.io/zh-cn/blog/nbss/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://quancs.github.io/zh-cn/blog/nbss/</guid><description>摘要 [1] Changsheng Quan, Xiaofei Li. Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training. In ICASSP 2022. [Code], [Pdf], [Results], [Examples]
本文基于深度学习技术解决了多通道多语音分离问题。 我们提出了一种端到端窄带网络，以STFT域的一个频率的多通道混合信号作为输入，输出该频率的分离信号。 在窄带（单个频带）上，空间信息的不同（或通道间差异）可以很好地区分不同位置的说话人。 这种差异在许多基于窄带的语音分离方法中被大量使用，例如波束成形和空间矢量聚类。 本文提出的网络通过训练来学习如何自动利用此信息，来得到语音分离的规则。 这样的规则对任何频率都是有效的，因此网络可以由所有频率共享。 此外，本文还提出了一种全频带的组合不变训练方法，以解决大多数窄带方法所遇到的频率组合问题。 实验表明，通过对窄带信息的深度学习，本文提出的方法优于使用真值的波束成形方法和最先进的基于深度学习的分离方法。
摘要 [2] Changsheng Quan, Xiaofei Li. Multichannel Speech Separation with Narrow-band Conformer. arXiv preprint arXiv:2204.04464. [Code], [Pdf], [Results], [Examples]
本文提出了一个多通道的语音分离网络narrow-band Conformer（简称NBC）。 这个网络经过训练后，可以自动探索如何利用窄带语音分离信息，例如多说话人的空间矢量聚类。 具体而言，在短时傅里叶变换（STFT）域中，网络由所有频率共享，其独立地处理每个频带。 对于一个频带，网络输入的是多通道混合信号的STFT系数，预测的是单说话人语音信号的STFT系数。 空间向量聚类与自注意力机制具有相似的原理，即计算向量的相似性，然后聚合相似的向量。 因此，Conformer特别适合窄带分离问题。 实验表明，相比其他先进的语音分离方法，本文所提出的narrow-band Conformer实现了更好的语音分离性能。
方法 本方法主要包括两个部分： 第一个部分是在单个频带上如何用网络进行分离； 第二个部分是关于如何去解决频率组合问题来训练神经网络。
以下内容假设麦克风个数为M，说话人个数为N。
1) 窄带语音分离 准备窄带的输入.</description></item></channel></rss>