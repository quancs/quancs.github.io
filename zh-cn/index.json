[{"title":"发表文献","date":"","description":"为中华之崛起而读书。   ——————周恩来","body":"2021 [4]\tChangsheng Quan and Xiaofei Li. 2021. Multi-channel Narrow-Band Deep Speech Separation with Full-band Permutation Invariant Training. arXiv preprint arXiv:2110.05966 (2021). [例子和介绍] [code] [pdf]\n[3]\tChangsheng Quan and Ping Guo. 2021. A local search method based on edge age strategy for minimum vertex cover problem in massive graphs. Expert Systems with Applications 182, (November 2021), 115185. DOI:https://doi.org/10.1016/j.eswa.2021.115185 [code]\n2019 [2]\tPing Guo, Changsheng Quan, and Haizhu Chen. 2019. MEAMVC: A Membrane Evolutionary Algorithm for Solving Minimum Vertex Cover Problem. IEEE Access 7, (2019), 60774–60784. DOI:https://doi.org/10.1109/ACCESS.2019.2915550 [code]\n[1]\tPing Guo, Changsheng Quan, and Lian Ye. 2019. UPSimulator: A general P system simulator. Knowledge-Based Systems 170, (April 2019), 20–25. DOI:https://doi.org/10.1016/j.knosys.2019.01.013 [code]\n","ref":"/zh-cn/publication/"},{"title":"深度窄带语音分离","date":"","description":"深度窄带语音分离和全频带组合不变训练","body":"  摘要 本文基于深度学习技术解决了多通道多语音分离问题。 我们提出了一种端到端窄带网络，以STFT域的一个频率的多通道混合信号作为输入，输出该频率的分离信号。 在窄带（单个频带）上，空间信息的不同（或通道间差异）可以很好地区分不同位置的说话人。 这种差异在许多基于窄带的语音分离方法中被大量使用，例如波束成形和空间矢量聚类。 本文提出的网络通过训练来学习如何自动利用此信息，来得到语音分离的规则。 这样的规则对任何频率都是有效的，因此网络可以由所有频率共享。 此外，本文还提出了一种全频带的组合不变训练方法，以解决大多数窄带方法所遇到的频率组合问题。 实验表明，通过对窄带信息的深度学习，本文提出的方法优于使用真值的波束成形方法和最先进的基于深度学习的分离方法。\n方法 本方法主要包括两个部分： 第一个部分是在单个频带上如何用网络进行分离； 第二个部分是关于如何去解决频率组合问题来训练神经网络。\n以下内容假设麦克风个数为M，说话人个数为N。\n1) 窄带语音分离 准备窄带的输入. 为什么选择窄带? 因为窄带包含了充足的不同说话人的空间信息。\n网络处理: 训练神经网络来实现在窄带输入上分离不同说话人的目的。\n2) 全频带组合不变训练（Full-band Permutation Invariant Training） 频率组合问题（Frequency Permutation Problem）——如何得到分离出的信号的跨频率的相关性？例子：两说话人情况下的一种可能的频率组合方式：\n本文提出的解决办法——频率绑定，强制认为在同一个输出位置的结果属于同一个说话人。\n损失函数\n$$ fPIT(\\boldsymbol{\\rm \\widehat{Y}}^{1},\\ldots, \\boldsymbol{\\rm \\widehat{Y}}^{N}, \\boldsymbol{\\rm {Y}}^{1},\\ldots,\\boldsymbol{\\rm {Y}}^{N})=\\mathop{min}_{p\\in \\mathcal{P}}\\frac{1}{N}\\sum_n \\mathcal{L}(\\boldsymbol{{\\rm {Y}}}^n,\\boldsymbol{{\\rm \\widehat{Y}}}^{p(n)}) $$\n其中，P是全部可能的频率组合组成的集合，p是其中一种可能的频率组合。 对于每对预测值和真值，负SI-SDR[1]被用来计算他们的损失。\n实验结果 在8通道2说话人情况下，和当前最佳分离算法的性能比较\n   模型 SDR SI-SDR NB-PESQ WB-PESQ     分离前 0.18 0.00 2.05 1.6   基于真值的MVDR [2] 12.19 11.70 3.21 2.68   FaSNet-TAC [3] 12.81 12.26 2.92 2.49   本文算法 13.89 13.26 3.31 2.87    例子    例子 混合语音 基于真值的MVDR FaSNet-TAC 本文算法     1             2             3             4             5             6              我们在窄带语音分离方向的新工作 Narrow-band Conformer 我们最近提出的Narrow-band Conformer[6]被用来替换本论文使用的BiLSTM网络。 因为窄带语音分离与Conformer中的自注意力机制（self-attention）、卷积操作具有相同的思想，因此Narrow-band Conformer相比BiLSTM更适合窄带上的语音分离。 实验结果显示Narrow-band Conformer的性能相比BiLSTM具有巨大的飞跃。\nNarrow-band Conformer的网络结构:\n Narrow-band Conformer论文中报告的结果 (8通道 2说话人)\n   Model #param NB-PESQ WB-PESQ SI-SDR RTF     Mixture - 2.05 1.59 0.0 -   Oracle MVDR [2] - 3.16 2.65 11.0 -   FaSNet-TAC [3] 2.8 M 2.96 2.53 12.6 0.67   SepFormer [4] 25.7 M 3.17 2.72 13.2 1.69   SepFormerMC 25.7 M 3.42 3.01 14.9 1.70   NB-BLSTM [5] 1.2 M 3.28 2.81 12.8 0.37   NBC [6] 2.0 M 4.00 3.78 20.3 1.32    Narrow-band Conformer论文涉及的算法的例子\n请使用Edge或者Chrome打开本网页，不要使用Firefox。Firefox播放语音存在问题。鼠标左键点击链接播放语音，右键下载\n   Id Mix Oracle MVDR [2] FaSNet-TAC [3] SepFormer[4] SepFormerMC NB-BLSTM [5] NBC [6]     1 mix spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2   2 mix spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2   3 mix spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2   4 mix spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2   5 mix spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2   6 mix spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2 spk1  spk2    源代码 本方法已在github上开源，见 [code], [NBSS with fPIT pdf] 和 [Narrow-band Conformer pdf]. 如果你喜欢我们的工作且愿意引用，请使用：\n@inproceedings{quan_multi-channel_2022, title = {Multi-channel {Narrow}-band {Deep} {Speech} {Separation} with {Full}-band {Permutation} {Invariant} {Training}}, booktitle = {{ICASSP}}, author = {Quan, Changsheng and Li, Xiaofei}, year = {2022}, } 以及\n@article{quan_multichannel_2022, title = {Multichannel {Speech} {Separation} with {Narrow}-band {Conformer}}, journal = {arXiv preprint arXiv:2204.04464}, author = {Quan, Changsheng and Li, Xiaofei}, year = {2022}, } 参考文献  [1] Jonathan Le Roux, Scott Wisdom, Hakan Erdogan, and John R. Hershey. SDR – Half-baked or Well Done? In ICASSP 2019. [2] https://github.com/Enny1991/beamformers [3] Yi Luo, Zhuo Chen, Nima Mesgarani, and Takuya Yoshioka. End-to-end Microphone Permutation and Number Invariant Multi-channel Speech Separation. In ICASSP 2020. [4] C. Subakan, M. Ravanelli, S. Cornell, M. Bronzi, and J. Zhong. Attention Is All You Need In Speech Separation. In ICASSP 2021. [5] Changsheng Quan, Xiaofei Li. **Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training**. In ICASSP 2022. [6] Changsheng Quan, Xiaofei Li. **Multichannel Speech Separation with Narrow-band Conformer**. arXiv preprint arXiv:2204.04464 ","ref":"/zh-cn/blog/nbss/"},{"title":"关于我","date":"","description":"一名西湖大学的博士研究生","body":"个人资料 我是西湖大学和浙江大学联合培养博士研究生，我的导师是 李晓飞教授 。我目前还是 西湖大学音频实验室 的一名成员。\n研究兴趣 我的研究兴趣主要包括机器学习和声音信号处理，具体包括语音分离、语音降噪、语音识别。\n更多 Github, Google Scholar\n","ref":"/zh-cn/about/"},{"title":"联络","date":"","description":"","body":"","ref":"/zh-cn/contact/"}]