[{"title":"Narrow-band Deep Speech Separation","date":"","description":"Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training","body":"   Abstract [1] Changsheng Quan, Xiaofei Li. Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training. In ICASSP 2022. [Code], [Pdf], [Results], [Examples]\nThis paper addresses the problem of multi-channel multi-speech separation based on deep learning techniques. In the short time Fourier transform domain, we propose an end-to-end narrow-band network that directly takes as input the multi-channel mixture signals of one frequency, and outputs the separated signals of this frequency. In narrow-band, the spatial information (or inter-channel difference) can well discriminate between speakers at different positions. This information is intensively used in many narrow-band speech separation methods, such as beamforming and clustering of spatial vectors. The proposed network is trained to learn a rule to automatically exploit this information and perform speech separation. Such a rule should be valid for any frequency, thence the network is shared by all frequencies. In addition, a full-band permutation invariant training criterion is proposed to solve the frequency permutation problem encountered by most narrow-band methods. Experiments show that, by focusing on deeply learning the narrow-band information, the proposed method outperforms the oracle beamforming method and the state-of-the-art deep learning based method.\n Abstract [2] Changsheng Quan, Xiaofei Li. Multichannel Speech Separation with Narrow-band Conformer. arXiv preprint arXiv:2204.04464. [Code], [Pdf], [Results], [Examples]\nThis work proposes a multichannel speech separation method with narrow-band Conformer (named NBC). The network is trained to learn to automatically exploit narrow-band speech separation information, such as spatial vector clustering of multiple speakers. Specifically, in the short-time Fourier transform (STFT) domain, the network processes each frequency independently, and is shared by all frequencies. For one frequency, the network inputs the STFT coefficients of multichannel mixture signals, and predicts the STFT coefficients of separated speech signals. Clustering of spatial vectors shares a similar principle with the self-attention mechanism in the sense of computing the similarity of vectors and then aggregating similar vectors. Therefore, Conformer would be especially suitable for the present problem. Experiments show that the proposed narrow-band Conformer achieves better speech separation performance than other state-of-the-art methods by a large margin.\n Method This method includes two main parts: the first part is to separate in each frequency; the second part is about how to solve the frequency permutation problem to train the network.\nThe following content assumes we have M microphones and N speakers.\n1) Narrow-band Deep Speech Separation Prepare Narrow-band Input. Why Narrow-band? It carries spatial information of speakers\nNetwork Processing: Train network to separate different speakers in narrow-band\n2) Full-band Permutation Invariant Training Frequency Permutation Problem\u0026mdash;How to find the correspondence of separated signals accross frequencies? One possible frequency permutation for two-speaker case:\nOur solution for FPP: Frequency Binding\u0026mdash;Force the separated signals at the same output position to belong to the same speaker\nLoss Calculation\n$$ fPIT(\\boldsymbol{\\rm \\widehat{Y}}^{1},\\ldots, \\boldsymbol{\\rm \\widehat{Y}}^{N}, \\boldsymbol{\\rm {Y}}^{1},\\ldots,\\boldsymbol{\\rm {Y}}^{N})=\\mathop{min}_{p\\in \\mathcal{P}}\\frac{1}{N}\\sum_n \\mathcal{L}(\\boldsymbol{{\\rm {Y}}}^n,\\boldsymbol{{\\rm \\widehat{Y}}}^{p(n)}) $$\nwhere P is the set of all possible frequency permutations, and p is one possible frequency permutation in P. And the negative SI-SDR [3] is used as the loss function for each prediction-target pair.\n Network NB-BLSTM The network used in our paper [1] is composed of two layers of bidirectional LSTM and one fully connected layer.\nNBC: Narrow-band Conformer The narrow-band conformer (NBC) proposed in our recent work [2] is used to replace the BiLSTM network used in [1], as the narrow-band speech separation shares a similar principle with the self-attention mechanism and convolutions in Conformer, thus is more suitable for narrow-band speech separation than BiLSTM. The narrow-band conformer significantly improves the performance of the BiLSTM network [1].\nThe narrow-band conformer structure:\n  Results Performance Comparision with SOTA Speech Separation Methods for 8-Channel 2-Speaker Mixtures\n   Model #param NB-PESQ WB-PESQ SI-SDR RTF     Mixture - 2.05 1.59 0.0 -   Oracle MVDR [4] - 3.16 2.65 11.0 -   FaSNet-TAC [5] 2.8 M 2.96 2.53 12.6 0.67   SepFormer [6] 25.7 M 3.17 2.72 13.2 1.69   SepFormerMC 25.7 M 3.42 3.01 14.9 1.70   NB-BLSTM [1] (prop.) 1.2 M 3.28 2.81 12.8 0.37   NBC [2] (prop.) 2.0 M 4.00 3.78 20.3 1.32     Examples Please open this page with Edge or Chrome, and not use Firefox. The audio playing is problematic in Firefox.\n   Id Mix Oracle MVDR [4] FaSNet-TAC [5] SepFormer [6] SepFormerMC NB-BLSTM [1] (prop.) NBC [2] (prop.)     1                      2                      3                      4                      5                      6                       mix  spk1  spk2\n Source Code These works are open sourced at github, see [Code], [NBSS with fPIT Pdf], [Narrow-band Conformer Pdf]. If you like this work and are willing to cite us, please use:\n@inproceedings{quan_multi-channel_2022, title = {Multi-channel {Narrow}-band {Deep} {Speech} {Separation} with {Full}-band {Permutation} {Invariant} {Training}}, booktitle = {{ICASSP}}, author = {Quan, Changsheng and Li, Xiaofei}, year = {2022}, } and\n@article{quan_multichannel_2022, title = {Multichannel {Speech} {Separation} with {Narrow}-band {Conformer}}, journal = {arXiv preprint arXiv:2204.04464}, author = {Quan, Changsheng and Li, Xiaofei}, year = {2022}, } References  [1] Changsheng Quan, Xiaofei Li. Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training. In ICASSP 2022.\n[2] Changsheng Quan, Xiaofei Li. Multichannel Speech Separation with Narrow-band Conformer. arXiv preprint arXiv:2204.04464 [3] Jonathan Le Roux, Scott Wisdom, Hakan Erdogan, and John R. Hershey. SDR – Half-baked or Well Done? In ICASSP 2019.\n[4] https://github.com/Enny1991/beamformers [5] Yi Luo, Zhuo Chen, Nima Mesgarani, and Takuya Yoshioka. End-to-end Microphone Permutation and Number Invariant Multi-channel Speech Separation. In ICASSP 2020.\n[6] C. Subakan, M. Ravanelli, S. Cornell, M. Bronzi, and J. Zhong. Attention Is All You Need In Speech Separation. In ICASSP 2021.\n","ref":"/blog/nbss/"},{"title":"Publication","date":"","description":"When the going gets tough, the tough get going.","body":"2021 [4]\tChangsheng Quan and Xiaofei Li. 2021. Multi-channel Narrow-Band Deep Speech Separation with Full-band Permutation Invariant Training. arXiv preprint arXiv:2110.05966 (2021). [examples and introduction] [code] [pdf]\n[3]\tChangsheng Quan and Ping Guo. 2021. A local search method based on edge age strategy for minimum vertex cover problem in massive graphs. Expert Systems with Applications 182, (November 2021), 115185. DOI:https://doi.org/10.1016/j.eswa.2021.115185 [code]\n2019 [2]\tPing Guo, Changsheng Quan, and Haizhu Chen. 2019. MEAMVC: A Membrane Evolutionary Algorithm for Solving Minimum Vertex Cover Problem. IEEE Access 7, (2019), 60774–60784. DOI:https://doi.org/10.1109/ACCESS.2019.2915550 [code]\n[1]\tPing Guo, Changsheng Quan, and Lian Ye. 2019. UPSimulator: A general P system simulator. Knowledge-Based Systems 170, (April 2019), 20–25. DOI:https://doi.org/10.1016/j.knosys.2019.01.013 [code]\n","ref":"/publication/"},{"title":"About Me","date":"","description":"A Computer Science PhD Student","body":"Personal Profile I am a joint Ph.D. student of Westlake University and Zhejiang University, advised by Dr. Xiaofei Li. Also, I am a member of Audio Laboratory in Westlake University, where I do my research work on Machine Learning, and Speech Separation.\nResearch My research interests include Machine Learning and Audio Signal Processing. Especially in, Speech Separation, Enhancement, ASR.\nMore Github, Google Scholar\n","ref":"/about/"},{"title":"Contact","date":"","description":"","body":"","ref":"/contact/"}]