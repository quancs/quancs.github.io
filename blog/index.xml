<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on Changsheng Quan</title><link>https://quancs.github.io/blog/</link><description>Recent content in Blog on Changsheng Quan</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 04 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://quancs.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Narrow-band Deep Speech Separation</title><link>https://quancs.github.io/blog/nbss/</link><pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate><guid>https://quancs.github.io/blog/nbss/</guid><description>Abstract This paper addresses the problem of multi-channel multi-speech separation based on deep learning techniques. In the short time Fourier transform domain, we propose an end-to-end narrow-band network that directly takes as input the multi-channel mixture signals of one frequency, and outputs the separated signals of this frequency. In narrow-band, the spatial information (or inter-channel difference) can well discriminate between speakers at different positions. This information is intensively used in many narrow-band speech separation methods, such as beamforming and clustering of spatial vectors.</description></item></channel></rss>