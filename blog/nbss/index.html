<!doctype html><html lang=en><head><meta charset=utf-8><title>Narrow-band Deep Speech Separation - Changsheng Quan</title><meta name=description content="Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=twitter:card content="summary_large_image"><meta property="og:site_name" content="Changsheng Quan"><meta property="og:title" content="Narrow-band Deep Speech Separation"><meta property="og:description" content="Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training"><meta property="og:type" content="article"><meta property="og:url" content="https://quancs.github.io/blog/nbss/"><meta property="og:image" content="https://quancs.github.io/img/main/logo.jpg"><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=generator content="Hugo 0.97.3"><link rel=stylesheet href=/css/bundle.min.95cbbf94d60e35b3dbbb8f4b3e4cb5047cf01280e691386b07a7f74d67068512.css integrity="sha256-lcu/lNYONbPbu49LPky1BHzwEoDmkThrB6f3TWcGhRI="><link rel=stylesheet href=/css/add-on.css></head><body><header id=site-header><nav id=site-nav><h1 class=nav-title><a href=/ class=nav>Blog</a></h1><menu id=site-nav-menu class="flyout-menu menu"><a href=/ class="nav link"><i class="fa fa-home"></i> Home</a>
<a href=/about class="nav link"><i class="far fa-id-card"></i> About Me</a>
<a href=/blog class="nav link"><i class="far fa-newspaper"></i> Blog</a>
<a href=/contact class="nav link"><i class="far fa-envelope"></i> Contact</a>
<a href=/publication class="nav link"><i class="far fa-newspaper"></i> Publication</a>
<a href=#search-input class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a></menu>
<a href=#search-input class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
<a href=#lang-menu class="nav lang-toggle" lang=en>en</a>
<a href=#site-nav class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a></nav><menu id=search class=menu><input id=search-input class="search-input menu"></input><div id=search-results class="search-results menu"></div></menu><menu id=lang-menu class="flyout-menu menu"><a href=# lang=en class="nav link active">English (en)</a>
<a href=https://quancs.github.io/zh-cn/blog/nbss/ lang=zh-cn class="nav link">中文 (简体) (zh-cn)</a></menu></header><div id=wrapper><section id=site-intro class=hidden-single-column><a href=/><img src=/img/main/logo.jpg class=circle width=100 alt="Changsheng Quan's Photo"></a><header><h1>Changsheng Quan</h1></header><main><p>A PhD Student of Computer Science</p></main><footer><ul class=socnet-icons><li><a href=//github.com/quancs target=_blank rel=noopener title=GitHub class="fab fa-github"></a></li><li><a href="//wpa.qq.com/msgrd?v=3&uin=1017241746&site=qq&menu=yes" target=_blank rel=noopener title=QQ class="fab fa-qq"></a></li><li><a href="//scholar.google.com/citations?user=prTK3NwAAAAJ" target=_blank rel=noopener title="Google Scholar"><i class="ai ai-google-scholar"></i></a></li><li><a href=mailto:quancs@qq.com target=_blank title=Email class="far fa-envelope"></a></li></ul></footer></section><main id=site-main><article><div class=post><header><div class=title><h2><a href=/blog/nbss/>Narrow-band Deep Speech Separation</a></h2><p>Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training</p></div><div class=meta><time datetime="2021-12-04 00:00:00 +0000 UTC">December 4, 2021</time><p>quancs</p><p>5-Minute Read</p></div></header><div id=socnet-share></div><div class=content><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>function play(e){const t=new Audio(e.getAttribute("href"));t.play()}</script><p>[1] Changsheng Quan, Xiaofei Li. <strong>Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training</strong>. In ICASSP 2022. <strong><a href=https://github.com/Audio-WestlakeU/NBSS>[<font color=DarkOrchid>Code</font>]</a></strong>, <strong><a href=https://arxiv.org/pdf/2110.05966>[<font color=DarkOrchid>Pdf</font>]</a></strong>, <strong><a href=#results>[<font color=DarkOrchid>Results</font>]</a></strong>, <strong><a href=#examples>[<font color=DarkOrchid>Examples</font>]</a></strong></p><h2 id=abstract>Abstract</h2><p>This paper addresses the problem of multi-channel multi-speech separation based on deep learning techniques.
In the short time Fourier transform domain, we propose an end-to-end narrow-band network that directly takes as input the multi-channel mixture signals of one frequency, and outputs the separated signals of this frequency.
In narrow-band, the spatial information (or inter-channel difference) can well discriminate between speakers at different positions.
This information is intensively used in many narrow-band speech separation methods, such as beamforming and clustering of spatial vectors.
The proposed network is trained to learn a rule to automatically exploit this information and perform speech separation.
Such a rule should be valid for any frequency, thence the network is shared by all frequencies.
In addition, a full-band permutation invariant training criterion is proposed to solve the frequency permutation problem encountered by most narrow-band methods.
Experiments show that, by focusing on deeply learning the narrow-band information, the proposed method outperforms the oracle beamforming method and the state-of-the-art deep learning based method.</p><hr><p>[2] Changsheng Quan, Xiaofei Li. <strong>Multichannel Speech Separation with Narrow-band Conformer</strong>. arXiv preprint arXiv:2204.04464. <strong><a href=https://github.com/Audio-WestlakeU/NBSS>[<font color=DarkOrchid>Code</font>]</a></strong>, <strong><a href=https://arxiv.org/abs/2204.04464>[<font color=DarkOrchid>Pdf</font>]</a></strong>, <strong><a href=#results>[<font color=DarkOrchid>Results</font>]</a></strong>, <strong><a href=#examples>[<font color=DarkOrchid>Examples</font>]</a></strong></p><h2 id=abstract-1>Abstract</h2><p>This work proposes a multichannel speech separation method with narrow-band Conformer (named NBC).
The network is trained to learn to automatically exploit narrow-band speech separation information, such as spatial vector clustering of multiple speakers.
Specifically, in the short-time Fourier transform (STFT) domain, the network processes each frequency independently, and is shared by all frequencies.
For one frequency, the network inputs the STFT coefficients of multichannel mixture signals, and predicts the STFT coefficients of separated speech signals.
Clustering of spatial vectors shares a similar principle with the self-attention mechanism in the sense of computing the similarity of vectors and then aggregating similar vectors.
Therefore, Conformer would be especially suitable for the present problem.
Experiments show that the proposed narrow-band Conformer achieves better speech separation performance than other state-of-the-art methods by a large margin.</p><hr><h2 id=method>Method</h2><p>This method includes two main parts:
the first part is to separate in each frequency;
the second part is about how to solve the frequency permutation problem to train the network.</p><p>The following content assumes we have <em>M</em> microphones and <em>N</em> speakers.</p><h3 id=1-narrow-band-deep-speech-separation>1) Narrow-band Deep Speech Separation</h3><p><strong>Prepare Narrow-band Input.</strong>
Why Narrow-band? It carries spatial information of speakers</p><p><img src=/blog/NBSS_examples/narrow_band_input.jpg alt=image title="from time domain to narrow-band input"></p><p><strong>Network Processing:</strong> Train network to separate different speakers in narrow-band</p><p><img src=/blog/NBSS_examples/network_processing.jpg alt=image2 title="Send narrow-band input to the network"></p><h3 id=2-full-band-permutation-invariant-training>2) Full-band Permutation Invariant Training</h3><p><strong>Frequency Permutation Problem</strong>&mdash;How to find the correspondence of separated signals accross frequencies? One possible frequency permutation for two-speaker case:</p><p><img src=/blog/NBSS_examples/fpp.jpg alt=image3></p><p>Our solution for FPP: <strong>Frequency Binding</strong>&mdash;Force the separated signals at the same output position to belong to the same speaker</p><p><img src=/blog/NBSS_examples/frequency_binding.jpg alt=image4></p><p><strong>Loss Calculation</strong></p><p>$$ fPIT(\boldsymbol{\rm \widehat{Y}}^{1},\ldots, \boldsymbol{\rm \widehat{Y}}^{N}, \boldsymbol{\rm {Y}}^{1},\ldots,\boldsymbol{\rm {Y}}^{N})=\mathop{min}_{p\in \mathcal{P}}\frac{1}{N}\sum_n \mathcal{L}(\boldsymbol{{\rm {Y}}}^n,\boldsymbol{{\rm \widehat{Y}}}^{p(n)}) $$</p><p>where <em>P</em> is the set of all possible frequency permutations, and <em>p</em> is one possible frequency permutation in <em>P</em>.
And the negative SI-SDR [3] is used as the loss function for each prediction-target pair.</p><hr><h2 id=network>Network</h2><h3 id=nb-blstm>NB-BLSTM</h3><p>The network used in our paper [1] is composed of two layers of bidirectional LSTM and one fully connected layer.</p><h3 id=nbc-narrow-band-conformer>NBC: Narrow-band Conformer</h3><p>The narrow-band conformer (NBC) proposed in our recent work [2] is used to replace the BiLSTM network used in [1], as the narrow-band speech separation shares a similar principle with the self-attention mechanism and convolutions in Conformer, thus is more suitable for narrow-band speech separation than BiLSTM.
The narrow-band conformer significantly improves the performance of the BiLSTM network [1].</p><p>The narrow-band conformer structure:</p><div align=center><img src=/blog/NBSS_examples/narrow-band_conformer.jpg height=300 alt="narrow-band conformer"></div><hr><h2 id=results>Results</h2><p>Performance Comparision with SOTA Speech Separation Methods for 8-Channel 2-Speaker Mixtures</p><table><thead><tr><th>Model</th><th style=text-align:right>#param</th><th style=text-align:right>NB-PESQ</th><th style=text-align:right>WB-PESQ</th><th style=text-align:right>SI-SDR</th><th style=text-align:right>RTF</th></tr></thead><tbody><tr><td>Mixture</td><td style=text-align:right>-</td><td style=text-align:right>2.05</td><td style=text-align:right>1.59</td><td style=text-align:right>0.0</td><td style=text-align:right>-</td></tr><tr><td>Oracle MVDR [4]</td><td style=text-align:right>-</td><td style=text-align:right>3.16</td><td style=text-align:right>2.65</td><td style=text-align:right>11.0</td><td style=text-align:right>-</td></tr><tr><td>FaSNet-TAC [5]</td><td style=text-align:right>2.8 M</td><td style=text-align:right>2.96</td><td style=text-align:right>2.53</td><td style=text-align:right>12.6</td><td style=text-align:right>0.67</td></tr><tr><td>SepFormer [6]</td><td style=text-align:right>25.7 M</td><td style=text-align:right>3.17</td><td style=text-align:right>2.72</td><td style=text-align:right>13.2</td><td style=text-align:right>1.69</td></tr><tr><td>SepFormerMC</td><td style=text-align:right>25.7 M</td><td style=text-align:right>3.42</td><td style=text-align:right>3.01</td><td style=text-align:right>14.9</td><td style=text-align:right>1.70</td></tr><tr><td>NB-BLSTM [1] (prop.)</td><td style=text-align:right>1.2 M</td><td style=text-align:right>3.28</td><td style=text-align:right>2.81</td><td style=text-align:right>12.8</td><td style=text-align:right>0.37</td></tr><tr><td>Narrow-band Conformer [2] (prop.)</td><td style=text-align:right>2.0 M</td><td style=text-align:right><strong>4.00</strong></td><td style=text-align:right><strong>3.78</strong></td><td style=text-align:right><strong>20.3</strong></td><td style=text-align:right>1.32</td></tr></tbody></table><hr><h2 id=examples>Examples</h2><p><small>Please open this page with Edge or Chrome, and not use Firefox. The audio playing is problematic in Firefox.</small></p><table><thead><tr><th>Id</th><th>Mix</th><th>Oracle MVDR [2]</th><th>FaSNet-TAC [3]</th><th>SepFormer[4]</th><th>SepFormerMC</th><th>NB-BLSTM [5]</th><th>NBC [6]</th></tr></thead><tbody><tr><td>1</td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_mix.wav>mix</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk1_p_MVDR.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk2_p_MVDR.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk1_p_FaSNet_TAC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk2_p_FaSNet_TAC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk1_p_SepFormer.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk2_p_SepFormer.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk1_p_SepFormerMC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk2_p_SepFormerMC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk1_p_NB-BLSTM.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk2_p_NB-BLSTM.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk1_p_NBC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/1_spk2_p_NBC.wav>spk2</a></td></tr><tr><td>2</td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_mix.wav>mix</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk1_p_MVDR.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk2_p_MVDR.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk1_p_FaSNet_TAC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk2_p_FaSNet_TAC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk1_p_SepFormer.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk2_p_SepFormer.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk1_p_SepFormerMC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk2_p_SepFormerMC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk1_p_NB-BLSTM.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk2_p_NB-BLSTM.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk1_p_NBC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/0_spk2_p_NBC.wav>spk2</a></td></tr><tr><td>3</td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_mix.wav>mix</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk1_p_MVDR.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk2_p_MVDR.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk1_p_FaSNet_TAC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk2_p_FaSNet_TAC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk1_p_SepFormer.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk2_p_SepFormer.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk1_p_SepFormerMC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk2_p_SepFormerMC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk1_p_NB-BLSTM.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk2_p_NB-BLSTM.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk1_p_NBC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/2_spk2_p_NBC.wav>spk2</a></td></tr><tr><td>4</td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_mix.wav>mix</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk1_p_MVDR.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk2_p_MVDR.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk1_p_FaSNet_TAC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk2_p_FaSNet_TAC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk1_p_SepFormer.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk2_p_SepFormer.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk1_p_SepFormerMC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk2_p_SepFormerMC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk1_p_NB-BLSTM.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk2_p_NB-BLSTM.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk1_p_NBC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/3_spk2_p_NBC.wav>spk2</a></td></tr><tr><td>5</td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_mix.wav>mix</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk1_p_MVDR.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk2_p_MVDR.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk1_p_FaSNet_TAC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk2_p_FaSNet_TAC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk1_p_SepFormer.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk2_p_SepFormer.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk1_p_SepFormerMC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk2_p_SepFormerMC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk1_p_NB-BLSTM.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk2_p_NB-BLSTM.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk1_p_NBC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/4_spk2_p_NBC.wav>spk2</a></td></tr><tr><td>6</td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_mix.wav>mix</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk1_p_MVDR.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk2_p_MVDR.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk1_p_FaSNet_TAC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk2_p_FaSNet_TAC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk1_p_SepFormer.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk2_p_SepFormer.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk1_p_SepFormerMC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk2_p_SepFormerMC.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk1_p_NB-BLSTM.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk2_p_NB-BLSTM.wav>spk2</a></td><td><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk1_p_NBC.wav>spk1</a></br><a onclick="return play(this),!1" href=/blog/NBC_examples/5_spk2_p_NBC.wav>spk2</a></td></tr></tbody></table><hr><h2 id=source-code>Source Code</h2><p>These works are open sourced at github, see <strong><a href=https://github.com/Audio-WestlakeU/NBSS>[<font color=DarkOrchid>Code</font>]</a></strong>, <strong><a href=https://arxiv.org/pdf/2110.05966>[<font color=DarkOrchid>NBSS with fPIT Pdf</font>]</a></strong>, <strong><a href=https://arxiv.org/abs/2204.04464>[<font color=DarkOrchid>Narrow-band Conformer Pdf</font>]</a></strong>. If you like this work and are willing to cite us, please use:</p><pre tabindex=0><code>@inproceedings{quan_multi-channel_2022,
	title = {Multi-channel {Narrow}-band {Deep} {Speech} {Separation} with {Full}-band {Permutation} {Invariant} {Training}},
	booktitle = {{ICASSP}},
	author = {Quan, Changsheng and Li, Xiaofei},
	year = {2022},
}
</code></pre><p>and</p><pre tabindex=0><code>@article{quan_multichannel_2022,
	title = {Multichannel {Speech} {Separation} with {Narrow}-band {Conformer}},
	journal = {arXiv preprint arXiv:2204.04464},
	author = {Quan, Changsheng and Li, Xiaofei},
	year = {2022},
}
</code></pre><h2 id=references>References</h2><small>[1] Changsheng Quan, Xiaofei Li. **Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training**. In ICASSP 2022.<br>[2] Changsheng Quan, Xiaofei Li. **Multichannel Speech Separation with Narrow-band Conformer**. arXiv preprint arXiv:2204.04464<br>[3] Jonathan Le Roux, Scott Wisdom, Hakan Erdogan, and John R. Hershey. SDR – Half-baked or Well Done? In ICASSP 2019.<br>[4] https://github.com/Enny1991/beamformers<br>[5] Yi Luo, Zhuo Chen, Nima Mesgarani, and Takuya Yoshioka. End-to-end Microphone Permutation and Number Invariant Multi-channel Speech Separation. In ICASSP 2020.<br>[6] C. Subakan, M. Ravanelli, S. Cornell, M. Bronzi, and J. Zhong. Attention Is All You Need In Speech Separation. In ICASSP 2021.<br></small></div><footer><div class=stats></div></footer></div></article><div class=pagination></div></main><section id=site-sidebar><section id=recent-posts><header><h1>Recent Posts</h1></header><article class=mini-post><header><h2><a href=/blog/nbss/>Narrow-band Deep Speech Separation</a></h2><time class=published datetime="2021-12-04 00:00:00 +0000 UTC">December 4, 2021</time></header></article></section></section><footer id=site-footer><p class=copyright>© 2021 Changsheng Quan<br>Theme: <a href=https://github.com/pacollins/hugo-future-imperfect-slim target=_blank rel=noopener>Hugo Future Imperfect Slim</a><br>A <a href=https://html5up.net/future-imperfect target=_blank rel=noopener>HTML5 UP port</a> | Powered by <a href=https://gohugo.io/ title=0.97.3 target=_blank rel=noopener>Hugo</a></p></footer><a id=back-to-top href=# class="fas fa-arrow-up fa-2x"></a>
<script src=/js/highlight.js></script>
<script>hljs.highlightAll()</script><script src=/js/bundle.min.b0f7e2c13ac227a41b2477895f343b74d3108e127d213d6ede46e84586bfc658.js integrity="sha256-sPfiwTrCJ6QbJHeJXzQ7dNMQjhJ9IT1u3kboRYa/xlg="></script>
<script src=/js/add-on.js></script></div></body></html>