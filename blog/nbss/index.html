<!doctype html><html lang=en><head><meta charset=utf-8><title>Narrow-band Deep Speech Separation - Changsheng Quan</title><meta name=description content="Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=twitter:card content="summary_large_image"><meta property="og:site_name" content="Changsheng Quan"><meta property="og:title" content="Narrow-band Deep Speech Separation"><meta property="og:description" content="Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training"><meta property="og:type" content="article"><meta property="og:url" content="https://quancs.github.io/blog/nbss/"><meta property="og:image" content="https://quancs.github.io/img/main/logo.jpg"><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=generator content="Hugo 0.96.0"><link rel=stylesheet href=/css/bundle.min.95cbbf94d60e35b3dbbb8f4b3e4cb5047cf01280e691386b07a7f74d67068512.css integrity="sha256-lcu/lNYONbPbu49LPky1BHzwEoDmkThrB6f3TWcGhRI="><link rel=stylesheet href=/css/add-on.css></head><body><header id=site-header><nav id=site-nav><h1 class=nav-title><a href=/ class=nav>Blog</a></h1><menu id=site-nav-menu class="flyout-menu menu"><a href=/ class="nav link"><i class="fa fa-home"></i> Home</a>
<a href=/about class="nav link"><i class="far fa-id-card"></i> About Me</a>
<a href=/blog class="nav link"><i class="far fa-newspaper"></i> Blog</a>
<a href=/contact class="nav link"><i class="far fa-envelope"></i> Contact</a>
<a href=/publication class="nav link"><i class="far fa-newspaper"></i> Publication</a>
<a href=#search-input class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a></menu>
<a href=#search-input class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
<a href=#lang-menu class="nav lang-toggle" lang=en>en</a>
<a href=#site-nav class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a></nav><menu id=search class=menu><input id=search-input class="search-input menu"></input><div id=search-results class="search-results menu"></div></menu><menu id=lang-menu class="flyout-menu menu"><a href=# lang=en class="nav link active">English (en)</a>
<a href=https://quancs.github.io/zh-cn/blog/nbss/ lang=zh-cn class="nav link">中文 (简体) (zh-cn)</a></menu></header><div id=wrapper><section id=site-intro class=hidden-single-column><a href=/><img src=/img/main/logo.jpg class=circle width=100 alt="Changsheng Quan's Photo"></a><header><h1>Changsheng Quan</h1></header><main><p>A PhD Student of Computer Science</p></main><footer><ul class=socnet-icons><li><a href=//github.com/quancs target=_blank rel=noopener title=GitHub class="fab fa-github"></a></li><li><a href="//wpa.qq.com/msgrd?v=3&uin=1017241746&site=qq&menu=yes" target=_blank rel=noopener title=QQ class="fab fa-qq"></a></li><li><a href="//scholar.google.com/citations?user=prTK3NwAAAAJ" target=_blank rel=noopener title="Google Scholar"><i class="ai ai-google-scholar"></i></a></li><li><a href=mailto:quancs@qq.com target=_blank title=Email class="far fa-envelope"></a></li></ul></footer></section><main id=site-main><article><div class=post><header><div class=title><h2><a href=/blog/nbss/>Narrow-band Deep Speech Separation</a></h2><p>Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training</p></div><div class=meta><time datetime="2021-12-04 00:00:00 +0000 UTC">December 4, 2021</time><p>quancs</p><p>4-Minute Read</p></div></header><div id=socnet-share></div><div class=content><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><h2 id=abstract>Abstract</h2><p>This paper addresses the problem of multi-channel multi-speech separation based on deep learning techniques.
In the short time Fourier transform domain, we propose an end-to-end narrow-band network that directly takes as input the multi-channel mixture signals of one frequency, and outputs the separated signals of this frequency.
In narrow-band, the spatial information (or inter-channel difference) can well discriminate between speakers at different positions.
This information is intensively used in many narrow-band speech separation methods, such as beamforming and clustering of spatial vectors.
The proposed network is trained to learn a rule to automatically exploit this information and perform speech separation.
Such a rule should be valid for any frequency, thence the network is shared by all frequencies.
In addition, a full-band permutation invariant training criterion is proposed to solve the frequency permutation problem encountered by most narrow-band methods.
Experiments show that, by focusing on deeply learning the narrow-band information, the proposed method outperforms the oracle beamforming method and the state-of-the-art deep learning based method.</p><h2 id=method>Method</h2><p>This method includes two main parts:
the first part is to separate in each frequency;
the second part is about how to solve the frequency permutation problem to train the network.</p><p>The following content assumes we have <em>M</em> microphones and <em>N</em> speakers.</p><h3 id=1-narrow-band-deep-speech-separation>1) Narrow-band Deep Speech Separation</h3><p><strong>Prepare Narrow-band Input.</strong>
Why Narrow-band? It carries spatial information of speakers</p><p><img src=/blog/NBSS_examples/narrow_band_input.jpg alt=image title="from time domain to narrow-band input"></p><p><strong>Network Processing:</strong> Train network to separate different speakers in narrow-band</p><p><img src=/blog/NBSS_examples/network_processing.jpg alt=image2 title="Send narrow-band input to the network"></p><h3 id=2-full-band-permutation-invariant-training>2) Full-band Permutation Invariant Training</h3><p><strong>Frequency Permutation Problem</strong>&mdash;How to find the correspondence of separated signals accross frequencies? One possible frequency permutation for two-speaker case:</p><p><img src=/blog/NBSS_examples/fpp.jpg alt=image3></p><p>Our solution for FPP: <strong>Frequency Binding</strong>&mdash;Force the separated signals at the same output position to belong to the same speaker</p><p><img src=/blog/NBSS_examples/frequency_binding.jpg alt=image4></p><p><strong>Loss Calculation</strong></p><p>$$ fPIT(\boldsymbol{\rm \widehat{Y}}^{1},\ldots, \boldsymbol{\rm \widehat{Y}}^{N}, \boldsymbol{\rm {Y}}^{1},\ldots,\boldsymbol{\rm {Y}}^{N})=\mathop{min}_{p\in \mathcal{P}}\frac{1}{N}\sum_n \mathcal{L}(\boldsymbol{{\rm {Y}}}^n,\boldsymbol{{\rm \widehat{Y}}}^{p(n)}) $$</p><p>where <em>P</em> is the set of all possible frequency permutations, and <em>p</em> is one possible frequency permutation in <em>P</em>.
And the negative SI-SDR [1] is used as the loss function for each prediction-target pair.</p><h2 id=results>Results</h2><p>Performance Comparision with SOTA Speech Separation Methods for 8-Channel 2-Speaker Mixtures</p><table><thead><tr><th>Model</th><th>SDR</th><th>SI-SDR</th><th>NB-PESQ</th><th>WB-PESQ</th></tr></thead><tbody><tr><td>Mixture</td><td>0.18</td><td>0.00</td><td>2.05</td><td>1.6</td></tr><tr><td>Oracle MVDR [2]</td><td>12.19</td><td>11.70</td><td>3.21</td><td>2.68</td></tr><tr><td>FaSNet-TAC [3]</td><td>12.81</td><td>12.26</td><td>2.92</td><td>2.49</td></tr><tr><td>prop.</td><td><strong>13.89</strong></td><td><strong>13.26</strong></td><td><strong>3.31</strong></td><td><strong>2.87</strong></td></tr></tbody></table><h2 id=examples>Examples</h2><table><thead><tr><th>Examples</th><th>Mix</th><th>Oracle MVDR [2]</th><th>FaSNet-TAC [3]</th><th>prop.</th></tr></thead><tbody><tr><td>1</td><td><audio controls src=/blog/NBSS_examples/1_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_NBSS.wav></audio></td></tr><tr><td>2</td><td><audio controls src=/blog/NBSS_examples/0_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_NBSS.wav></audio></td></tr><tr><td>3</td><td><audio controls src=/blog/NBSS_examples/2_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_NBSS.wav></audio></td></tr><tr><td>4</td><td><audio controls src=/blog/NBSS_examples/3_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_NBSS.wav></audio></td></tr><tr><td>5</td><td><audio controls src=/blog/NBSS_examples/4_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_NBSS.wav></audio></td></tr><tr><td>6</td><td><audio controls src=/blog/NBSS_examples/5_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_NBSS.wav></audio></td></tr></tbody></table><h2 id=new-works-on-narrow-band-speech-separation>New Works on Narrow-band Speech Separation</h2><h3 id=narrow-band-conformer>Narrow-band Conformer</h3><p>The narrow-band conformer (NBC) proposed in our recent work [6] is used to replace the BiLSTM network used in this paper, as the narrow-band speech separation shares a similar principle with the self-attention mechanism and convolutions in Conformer, thus is more suitable for narrow-band speech separation than BiLSTM.
The narrow-band conformer significantly improves the performance of the BiLSTM network [5].</p><p>The narrow-band conformer structure:</p><div align=center><img src=/blog/NBSS_examples/narrow-band_conformer.jpg height=300 alt="narrow-band conformer"></div><p>The results reported in narrow-band conformer [6] (8-Channel 2-Speaker Mixtures):</p><table><thead><tr><th>Model</th><th style=text-align:right>#param</th><th style=text-align:right>NB-PESQ</th><th style=text-align:right>WB-PESQ</th><th style=text-align:right>SI-SDR</th><th style=text-align:right>RTF</th></tr></thead><tbody><tr><td>Mixture</td><td style=text-align:right>-</td><td style=text-align:right>2.05</td><td style=text-align:right>1.59</td><td style=text-align:right>0.0</td><td style=text-align:right>-</td></tr><tr><td>Oracle MVDR [2]</td><td style=text-align:right>-</td><td style=text-align:right>3.16</td><td style=text-align:right>2.65</td><td style=text-align:right>11.0</td><td style=text-align:right>-</td></tr><tr><td>FaSNet-TAC [3]</td><td style=text-align:right>2.8 M</td><td style=text-align:right>2.96</td><td style=text-align:right>2.53</td><td style=text-align:right>12.6</td><td style=text-align:right>0.67</td></tr><tr><td>SepFormer [4]</td><td style=text-align:right>25.7 M</td><td style=text-align:right>3.17</td><td style=text-align:right>2.72</td><td style=text-align:right>13.2</td><td style=text-align:right>1.69</td></tr><tr><td>SepFormerMC</td><td style=text-align:right>25.7 M</td><td style=text-align:right>3.42</td><td style=text-align:right>3.01</td><td style=text-align:right>14.9</td><td style=text-align:right>1.70</td></tr><tr><td>NB-BLSTM [5]</td><td style=text-align:right>1.2 M</td><td style=text-align:right>3.28</td><td style=text-align:right>2.81</td><td style=text-align:right>12.8</td><td style=text-align:right>0.37</td></tr><tr><td>NBC [6]</td><td style=text-align:right>2.0 M</td><td style=text-align:right><strong>4.00</strong></td><td style=text-align:right><strong>3.78</strong></td><td style=text-align:right><strong>20.3</strong></td><td style=text-align:right>1.32</td></tr></tbody></table><table><thead><tr><th>Examples</th><th>Mix</th><th>Oracle MVDR [2]</th><th>FaSNet-TAC [3]</th><th>SepFormer[4]</th><th>SepFormerMC</th><th>NB-BLSTM [5]</th><th>NBC [6]</th></tr></thead><tbody><tr><td>1</td><td><audio controls src=/blog/NBSS_examples/1_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/1_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/1_spk2_p_NBSS.wav></audio></td></tr><tr><td>2</td><td><audio controls src=/blog/NBSS_examples/0_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/0_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/0_spk2_p_NBSS.wav></audio></td></tr><tr><td>3</td><td><audio controls src=/blog/NBSS_examples/2_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/2_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/2_spk2_p_NBSS.wav></audio></td></tr><tr><td>4</td><td><audio controls src=/blog/NBSS_examples/3_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/3_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/3_spk2_p_NBSS.wav></audio></td></tr><tr><td>5</td><td><audio controls src=/blog/NBSS_examples/4_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/4_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/4_spk2_p_NBSS.wav></audio></td></tr><tr><td>6</td><td><audio controls src=/blog/NBSS_examples/5_mix.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_MVDR.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_MVDR.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_TAC.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_TAC.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_NBSS.wav></audio></td><td><audio controls src=/blog/NBSS_examples/5_spk1_p_NBSS.wav></audio></br><audio controls src=/blog/NBSS_examples/5_spk2_p_NBSS.wav></audio></td></tr></tbody></table><h2 id=source-code>Source Code</h2><p>These works are open sourced at github, see <strong><a href=https://github.com/quancs/NBSS>[<font color=DarkOrchid>code</font>]</a></strong>, <strong><a href=https://arxiv.org/pdf/2110.05966>[<font color=DarkOrchid>NBSS with fPIT pdf</font>]</a></strong>, <strong><a href=https://arxiv.org/abs/2204.04464>[<font color=DarkOrchid>Narrow-band Conformer pdf</font>]</a></strong>. If you like this work and are willing to cite us, please use:</p><pre tabindex=0><code>@inproceedings{quan_multi-channel_2022,
	title = {Multi-channel {Narrow}-band {Deep} {Speech} {Separation} with {Full}-band {Permutation} {Invariant} {Training}},
	booktitle = {{ICASSP}},
	author = {Quan, Changsheng and Li, Xiaofei},
	year = {2022},
}
</code></pre><p>and</p><pre tabindex=0><code>@article{quan_multichannel_2022,
	title = {Multichannel {Speech} {Separation} with {Narrow}-band {Conformer}},
	journal = {arXiv preprint arXiv:2204.04464},
	author = {Quan, Changsheng and Li, Xiaofei},
	year = {2022},
}
</code></pre><h2 id=references>References</h2><small>[1] Jonathan Le Roux, Scott Wisdom, Hakan Erdogan, and John R. Hershey. SDR – Half-baked or Well Done? In ICASSP 2019.<p>[2] <a href=https://github.com/Enny1991/beamformers>https://github.com/Enny1991/beamformers</a></p><p>[3] Yi Luo, Zhuo Chen, Nima Mesgarani, and Takuya Yoshioka. End-to-end Microphone Permutation and Number Invariant Multi-channel Speech Separation. In ICASSP 2020.</p><p>[4] C. Subakan, M. Ravanelli, S. Cornell, M. Bronzi, and J. Zhong. Attention Is All You Need In Speech Separation. In ICASSP 2021.</p><p>[5] Changsheng Quan, Xiaofei Li. <strong>Multi-channel Narrow-band Deep Speech Separation with Full-band Permutation Invariant Training</strong>. In ICASSP 2022.</p><p>[6] Changsheng Quan, Xiaofei Li. <strong>Multichannel Speech Separation with Narrow-band Conformer</strong>. arXiv preprint arXiv:2204.04464</small></p></div><footer><div class=stats></div></footer></div></article><div class=pagination></div></main><section id=site-sidebar><section id=recent-posts><header><h1>Recent Posts</h1></header><article class=mini-post><header><h2><a href=/blog/nbss/>Narrow-band Deep Speech Separation</a></h2><time class=published datetime="2021-12-04 00:00:00 +0000 UTC">December 4, 2021</time></header></article></section></section><footer id=site-footer><p class=copyright>© 2021 Changsheng Quan<br>Theme: <a href=https://github.com/pacollins/hugo-future-imperfect-slim target=_blank rel=noopener>Hugo Future Imperfect Slim</a><br>A <a href=https://html5up.net/future-imperfect target=_blank rel=noopener>HTML5 UP port</a> | Powered by <a href=https://gohugo.io/ title=0.96.0 target=_blank rel=noopener>Hugo</a></p></footer><a id=back-to-top href=# class="fas fa-arrow-up fa-2x"></a>
<script src=/js/highlight.js></script>
<script>hljs.highlightAll()</script><script src=/js/bundle.min.48c41bc4c97614979bd6ed3c7e4458f42942e82c91891a017e4943ba78afc8c0.js integrity="sha256-SMQbxMl2FJeb1u08fkRY9ClC6CyRiRoBfklDunivyMA="></script>
<script src=/js/add-on.js></script></div></body></html>